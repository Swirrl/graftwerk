#+TITLE: Graftwerk :: Pipeline Runner API Docs

* Getting Started

** Running the Graftwerk Server

Graftwerk uses clojail and Java SecurityManagers to sandbox the
execution of certain code.  For development it is recommended that you
put the following java policy in your home directory, but production
users should use something with stronger permissions.  Without it you
will likely experience =java.security.AccessControlException='s.

#+BEGIN_SRC text
grant {
  permission java.security.AllPermission;
};
#+END_SRC

Alternatively this can be set by setting the system property
=java.security.policy= at jvm startup e.g.

#+BEGIN_SRC text
java -jar graftwerk.jar -Djava.security.policy==~/.java.policy
#+END_SRC

You can build a release for Dapaas with: =lein uberjar=

Starting the server can then be done with

=java -jar graftwerk.jar=

Or run in development with:

=lein repl=

The server will start on port 3000 visiting the following URL will
send you to a test page where you can test the app and inspect some of
the requests from your web browsers dev tools:

[[http://localhost:3000/][http://localhost:3000/]]

NOTE: that testing in a browser may be misleading because the browser
sets different accept headers.

* Running Pipelines

The server provides two routes for running both pipes and grafts,
there are also two test forms which can be used to fasion well formed
requests via the web browser.

It is recommended that you test both of these routes first to
understand how the system works.  You can preview these network
requests from your browser in the Firefox or Chrome dev tools.  This
will give you an idea about how to recreate them programmatically;
though beware that the accept headers the browser sends will be
different; and force graftwerk to return a default encoding.

** Test Data

We provide two files of test data =example_pipeline.clj= and
=example-data.csv=.  The server currently only works with CSV files as
input, Excel file support will be added in the future.

Lets look at the pipeline code:

#+BEGIN_SRC clojure
(defn ->integer
  "An example transformation function that converts a string to an integer"
  [s]
  (Integer/parseInt s))

(def base-domain (prefixer "http://my-domain.com"))

(def base-graph (prefixer (base-domain "/graph/")))

(def base-id (prefixer (base-domain "/id/")))

(def base-vocab (prefixer (base-domain "/def/")))

(def base-data (prefixer (base-domain "/data/")))

(def make-graph
  (graph-fn [{:keys [name sex age person-uri gender]}]
            (graph (base-graph "example")
                   [person-uri
                    [rdf:a foaf:Person]
                    [foaf:gender sex]
                    [foaf:age age]
                    [foaf:name (s name)]])))

(defpipe my-pipe
  "Pipeline to convert tabular persons data into a different tabular format."
  [data-file]
  (-> (read-dataset data-file :format :csv)
      (drop-rows 1)
      (make-dataset [:name :sex :age])
      (derive-column :person-uri [:name] base-id)
      (mapc {:age ->integer
             :sex {"f" (s "female")
                   "m" (s "male")}})))


(defgraft my-graft
  "Pipeline to convert the tabular persons data sheet into graph data."
  my-pipe make-graph)
#+END_SRC

The important thing to notice is that for security reasons it doesn't
include a namespace defintion.  Thats because this is set by the
server.  Currently this is hardcoded in the server, but will be
configurable (server side) in the future.  This is the default context
that pipelines execute in:

#+BEGIN_SRC clojure
  (ns graftwerk.pipele
    (:require
     [grafter.tabular :refer [defpipe defgraft column-names columns rows
                              all-columns derive-column mapc swap drop-rows
                              read-dataset read-datasets make-dataset
                              move-first-row-to-header _ graph-fn
                              test-dataset]]
     [grafter.rdf :refer [s prefixer]]
     [grafter.rdf.protocols :refer [->Quad]]
     [grafter.rdf.templater :refer [graph]]
     [grafter.vocabularies.rdf :refer :all]
     [grafter.vocabularies.foaf :refer :all]))
#+END_SRC

** Running Pipes

- Visit [[http://localhost:3000/pipe][/pipe]] in your browser to access the test form for pipes.

** Runnings Grafts

- Visit [[http://localhost:3000/graft][/graft]] in your browser to access the test form for grafts.

* API

*NOTE:* The Graftwerk pipeline runner is a stateless service.  You
submit requests to it, and receive responses.  It does not persist any
state across requests.

** Response Codes

The following response codes may be returned on requests:

| Status Code | Name                   | Meaning                                                                                                    |
|-------------+------------------------+------------------------------------------------------------------------------------------------------------|
|         200 | Ok                     | The result will be in the response                                                                         |
|         404 | Not Found              | Invalid service route                                                                                      |
|         415 | Unsupported Media Type | The server did not understand the supplied data, e.g. a file format that we don't understand was supplied. |
|         422 | Unprocessable Entity   | The data is understood, but still invalid.  The response object may contain more information.              |
|         500 | Server Error           | An error occured.  An error object may be returned in the response.                                        |

** Evaluating a Pipeline as a pipe

| Route            | Method |
|------------------+--------|
| =/evaluate/pipe= | =POST= |

Sending a =POST= request to =/pipe/evaluate= will evaluate the
pipeline returning the result based upon the accept header.

*** Required Parameters

The POSTs body =MUST= contain valid =multipart/form-data= and =MUST=
have the =Content-Type= of the request set to =multipart/form-data=.
For more details see the [[http://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.2][W3C recommendations on Form Content Types]].

The form data =MUST= consist of the following parts:

| Name (form key) | Description                                 | Content-Disposition |
|-----------------+---------------------------------------------+---------------------|
| pipeline        | The Grafter Pipeline Code                   | file                |
| data            | The input file to be transformed            | file                |
| command         | The name of the pipe/graft function to call | form-data           |

If your pipeline code contains a pipe you want to execute, you must
set the command to be the unqualified name of the function.  e.g. to
run the pipe below you would set command to =my-pipeline=.  This works
the same for grafts.

#+BEGIN_SRC clojure
(defpipe my-pipeline [dataset]
  (-> (read-dataset dataset)
      (operation ...)
      (operation ...)
      (operation ...)))
#+END_SRC

/NOTE:/ we plan to add support for Excel formats in the future, but
this is currently unsupported.

*** Response Formats

The =/pipe= route is used to execute the =pipe= part of a
transformation and consequently can only return tabular data formats,
it should not be used to execute grafts.

Clients =SHOULD= specify the format they want by setting the accept
header of the request, or by supplying a format parameter on the URL.
If no valid format is specified EDN will be returned for pipe routes
and n-triples for grafts.

It =SHALL= support the following response formats:

| Route Type | Accept Header         |
|------------+-----------------------|
| pipe       | application/edn       |
| pipe       | text/csv              |
| graft      | application/n-triples |

** Pagination Parameters

/NOTE:/ Pagination is not supported yet on the graft route, currently
graft runs return only all of the results as n-triples.  We will add
support for specifying a portion of this output for previews.

If no page number is supplied then the pipeline will return the
results of the whole pipeline execution in the specified format.

If however the interface wishes to render a preview of the
transformation on a page of data it can request just these results

The route supports the following optional parameters:

| Parameter   | Type    | Action                                                          |
|-------------+---------+-----------------------------------------------------------------|
| =page=      | Integer | Requests the page number =page=.  Assuming =page-size= results. |
| =page-size= | Integer | Page must be specified                                          |

Pages start at page =0=, and there is a default page size of =50=
results.

** Response Objects

Responses are in EDN as the format can correctly convey type
information which would need additional work to represent in JSON.

*** Tabular Data

Pipes support EDN and CSV formats depending on the accept header.  The
EDN representation of a tabular dataset will follow this structure:

#+BEGIN_SRC clojure
 { :column-names ["one" :two "three"]
   :rows [{"one" 1 :two 2 "three" 3}
          {"one" 2 :two 4 "three" 6}] }
#+END_SRC

*** TODO Error Objects

/NOTE this is not yet supported/

Error objects will be defined as EDN tagged literals and have the
following properties:

#+BEGIN_SRC clojure
#grafter.edn/Error {
 :type "java.lang.NullPointerException"
 :message "An error message"
 :stacktrace "..."
}
#+END_SRC

HTTP Status codes are used indicate most high level errors, however
more details on the error may be contained in an EDN Error object.

Error objects may in the future also be returned inside Datasets at
either the row level, or cell level.

* Notes

<<<<<<< HEAD
#+BEGIN_SRC clojure
#grafter.edn/Dataset { :column-names ["one" :two "three"]
                       :rows [{"one" 1 :two 2 "three" 3}
                              {"one" 2 :two 4 "three" 6}] }
#+END_SRC

* License

Licensed under the Eclipse Public License.  (c) 2015 Swirrl IT Ltd.
